---
title: "Assignment 7-607"
author: "Sangeetha Sasikumar"
date: "11/6/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidytext)
library(devtools)
library(dplyr)
library(textdata)
library(tidyr)
library(janeaustenr)
library(dplyr)
library(stringr)
library(ggplot2)
library(pdftools)
library(wordcloud)
```
Example from https://www.tidytextmining.com/sentiment.html. This was something very new to me, so I kept it all in the markdown. 

```{r}
get_sentiments("afinn")
get_sentiments("bing")
get_sentiments("nrc")
# lexicons <- c(‘bing’, ‘afinn’, ‘loughran’, ‘nrc’)
# for (lex in lexicons) {
#     print(paste0(“lexicon: “, lex))
#     print(get_sentiments(lex))
```


```{r}


tidy_books <- austen_books() %>%
  group_by(book) %>%
  mutate(
    linenumber = row_number(),
    chapter = cumsum(str_detect(text, 
                                regex("^chapter [\\divxlc]", 
                                      ignore_case = TRUE)))) %>%
  ungroup() %>%
  unnest_tokens(word, text)

nrc_joy <- get_sentiments("nrc") %>% 
  filter(sentiment == "joy")

tidy_books %>%
  filter(book == "Emma") %>%
  inner_join(nrc_joy) %>%
  count(word, sort = TRUE)

```

```{r}
jane_austen_sentiment <- tidy_books %>%
  inner_join(get_sentiments("bing")) %>%
  count(book, index = linenumber %/% 80, sentiment) %>%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>% 
  mutate(sentiment = positive - negative)

jane_austen_sentiment

ggplot(jane_austen_sentiment, aes(index, sentiment, fill = book)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~book, ncol = 2, scales = "free_x")

```

Loading the gutenbergr library to decide which book I want to analyze
```{r}
library("gutenbergr")
print(gutenberg_metadata, n=50)

```

My analysis on The Legend of Sleepy Hollow: I have never read this book, however I love the movie. It's such a good haunting story. 
```{r}
chosen_book <- gutenberg_works(title  == "The Legend of Sleepy Hollow")
chosen_book
class(chosen_book)
#chosen_book<-as.data.frame(chosen_book)
class(chosen_book)
#I had to come back and redo this as a download since the analysis was getting messed up as a df
sleepy <- gutenberg_download(41)

text <- tibble(line = 1:nrow(sleepy), sleepy$text)
colnames(text) <- c('lines', 'text')


book <- text  %>%
  unnest_tokens(word, text) #splits a columns into tokens

#counting list of positive words
book  %>%
  inner_join(get_sentiments("bing"))  %>%
  count(word, sort = TRUE)
```
#Making my word cloud for negative words. 
```{r}

book %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100, colors=brewer.pal(8, "Dark2")))

```

Making wordcloud for negative words
```{r}

book %>%
  inner_join(get_sentiments("nrc")) %>%
  anti_join(stop_words) %>%
  count(word)%>% with(wordcloud(word, n, max.words = 100, colors=brewer.pal(8, "Dark2")))

```

```{r}
bing_word<- book %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort=TRUE)

bing_word %>%
  group_by(sentiment) %>% top_n(10) %>% ggplot(aes(reorder(word, n), n, fill = sentiment)) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Sentiment Comparison of Negative vs Positive", x = NULL) +
  coord_flip()

```

The words I got for positive and negative make sense. It's quite a chilling story, although I don't know the author's syntax/style. The Legend of Sleepy Hollow is a favorite horror story of mine and I love the town of Sleepy Hollow! Sentiment analysis was an interesting topic to learn. I changed my dataset twice, and ended up choosing the book within the package because I wanted to choose something more comfortable while I am still learning a new topic. 

```{r}
book  %>%
  inner_join(get_sentiments("afinn"))  %>%
  count(word, sort = TRUE)

book %>%
  anti_join(stop_words) %>% count(word) %>%
  with(wordcloud(word, n, max.words = 100, colors=brewer.pal(8, "Dark2")))


```

Above I started doing wordcloud for "afinn", but I did not get time to finish. If Prof. Catlin gives me a chance to redo this assignment, I can clean this all up. 


Citations:
Afinn: This dataset was published in Saif M. Mohammad and Peter Turney. (2013), ``Crowdsourcing a Word-Emotion Association Lexicon.'' Computational Intelligence, 29(3): 436-465.
article{mohammad13,
author = {Mohammad, Saif M. and Turney, Peter D.},
title = {Crowdsourcing a Word-Emotion Association Lexicon},
journal = {Computational Intelligence},
volume = {29},
number = {3},
pages = {436-465},
doi = {10.1111/j.1467-8640.2012.00460.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-8640.2012.00460.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8640.2012.00460.x},
year = {2013}
